{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mariel', 'Uriel']\n",
      "['Estudiante', 'Practicante']\n",
      "['14', '21']\n"
     ]
    }
   ],
   "source": [
    "Datos = []\n",
    "Nombres = []\n",
    "Cargos = []\n",
    "Edades = []\n",
    "entrar_salir = [False,False]\n",
    "\n",
    "datosPath = 'C:/Users/uriel/OneDrive - Universidad de Guanajuato/Documentos/8vo semestre/Forte/Datos'\n",
    "peopleList = os.listdir(datosPath)\n",
    "for person in peopleList: \n",
    "    filePathPerson = datosPath + '/' + person\n",
    "    with open(filePathPerson, \"r\") as file:\n",
    "        Datos.append(file.readlines())\n",
    "\n",
    "\n",
    "for Dato in Datos:\n",
    "    aux = Dato[0].split()\n",
    "    Nombres.append(aux[1])\n",
    "    aux = Dato[2].split()\n",
    "    Cargos.append(aux[1])\n",
    "    aux = Dato[4].split()\n",
    "    Edades.append(aux[1])\n",
    "    \n",
    "print(Nombres)\n",
    "print(Cargos)\n",
    "print(Edades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Leyendo el modelo\n",
    "#face_recognizer.read('modeloEigenFace.xml')\n",
    "#face_recognizer.read('modeloFisherFace_UyM.xml')\n",
    "face_recognizer.read('modeloLBPHFace_UyM.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection # Es el detector de rostros\n",
    "mp_drawing = mp.solutions.drawing_utils # Esto es para colocar el recuadro y los puntos\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "    with mp_face_detection.FaceDetection(  # Gestor de contexto\n",
    "        min_detection_confidence=0.6) as face_detection:\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read() # Comenzamos a leer el video\n",
    "            if ret == False: break # Verificamos si se esta leyendo de forma correcta\n",
    "            frame = imutils.resize(frame, width=640)\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            aux_frame = frame.copy()\n",
    "            height, width, _ = frame.shape # Obtenemos las dimensipones de la imagen\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # cv2 lo lee como BGR y lo convertimos a RGB       \n",
    "            results = face_detection.process(frame_rgb) # Obtenemos las cordenadas de la cara y de los puntos de interes\n",
    "            malla = face_mesh.process(frame_rgb)\n",
    "            k = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            \n",
    "            if results.detections is not None: # Si detecta un rostro entra aqui \n",
    "                if malla.multi_face_landmarks is not None:\n",
    "                    for face_landmarks in malla.multi_face_landmarks:\n",
    "                        \n",
    "                        longitud = []\n",
    "                        for detection in results.detections:\n",
    "                            w = int(detection.location_data.relative_bounding_box.width * width)\n",
    "                            h = int(detection.location_data.relative_bounding_box.height * height)\n",
    "                            longitud.append(w+h)\n",
    "\n",
    "                        id_min = longitud.index(max(longitud))  \n",
    "                        face = results.detections[id_min]\n",
    "                        x = int(face.location_data.relative_bounding_box.xmin * width)\n",
    "                        y = int(face.location_data.relative_bounding_box.ymin * height)    \n",
    "\n",
    "                        # Recortamos el rostro y reajustamos el tama√±o\n",
    "                        rostro = aux_frame[y:y+h,x:x+w]\n",
    "                        try:\n",
    "                            rostro = cv2.resize(rostro,(150,150), interpolation=cv2.INTER_CUBIC)\n",
    "                            rostro = cv2.cvtColor(rostro, cv2.COLOR_BGR2GRAY)\n",
    "                            label = face_recognizer.predict(rostro)\n",
    "                            cv2.putText(frame,'{}'.format(label),(x,y-5),1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
    "                            coord_x_text = x-w-45\n",
    "\n",
    "                            if label[1] < 110:\n",
    "                                cv2.putText(frame,'Nombre:{}'.format(Nombres[label[0]]),(coord_x_text,y-65),2,1.1,(255,0,0),1,cv2.LINE_AA)\n",
    "                                cv2.putText(frame,'Cargo:{}'.format(Cargos[label[0]]),(coord_x_text,y-30),1,2.1,(255,0,0),1,cv2.LINE_AA)\n",
    "                                cv2.putText(frame,'Edad:{}'.format(Edades[label[0]]),(coord_x_text,y+5),1,2.1,(255,0,0),1,cv2.LINE_AA)   \n",
    "                                #cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)   \n",
    "                                mp_drawing.draw_landmarks(frame, face_landmarks,\n",
    "                                    mp_face_mesh.FACEMESH_CONTOURS , #FACEMESH_TESSELATION FACEMESH_CONTOURS  FACE_CONNECTIONS\n",
    "                                    mp_drawing.DrawingSpec(color=(0,255, 0), thickness=1, circle_radius=1),\n",
    "                                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=1))\n",
    "\n",
    "                            else:\n",
    "                                cv2.putText(frame,'Desconocido',(coord_x_text,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "                                #cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "                                mp_drawing.draw_landmarks(frame, face_landmarks,\n",
    "                                    mp_face_mesh.FACEMESH_CONTOURS , #FACEMESH_TESSELATION FACEMESH_CONTOURS  FACE_CONNECTIONS\n",
    "                                    mp_drawing.DrawingSpec(color=(0,0, 255), thickness=1, circle_radius=1),\n",
    "                                    mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=1))\n",
    "\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            cv2.imshow(\"frame\", frame) # Muestra lo que esta detectando \n",
    "            if k == 27: break# Si tecleamos la tecla esc se cancela o si llega a 300\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
